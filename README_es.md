\
> [!NOTE]
> Nota: Este documento es una versi√≥n traducida autom√°ticamente y puede contener imprecisiones. ¬°Agradecemos sus contribuciones para mejorar la traducci√≥n!

<!-- SPDX-License-Identifier: Apache-2.0 OR CC BY 4.0 OR other -->
<div align="center"><b><a href="README.md">English</a> | <a href="README_zh.md">ÁÆÄ‰Ωì‰∏≠Êñá</a> | <a href="README_ja.md">Êó•Êú¨Ë™û</a> | <a href="README_es.md">Espa√±ol</a> | <a href="README_fr.md">Fran√ßais</a></b></div>

<h1 align="center" style="border: none">
    <div style="border: none">
        <!-- Si tienes un logo, puedes a√±adirlo aqu√≠. Ejemplo:
        <a href="YOUR_PROJECT_LINK"><picture>
            <source media="(prefers-color-scheme: dark)" srcset="PATH_TO_DARK_LOGO.svg">
            <source media="(prefers-color-scheme: light)" srcset="PATH_TO_LIGHT_LOGO.svg">
            <img alt="Logo del Proyecto" src="PATH_TO_LIGHT_LOGO.svg" width="200" />
        </picture></a>
        <br>
        -->
        Tiny QA Benchmark++ (TQB++)
    </div>
</h1>

<p align="center">
Un conjunto de datos de evaluaci√≥n ultraligero y un generador sint√©tico <br>para exponer fallos cr√≠ticos de LLM en segundos, ideal para CI/CD y LLMOps.
</p>

<div align="center">
    <a href="https://pypi.org/project/tinyqabenchmarkpp/"><img alt="Versi√≥n de PyPI" src="https://img.shields.io/pypi/v/tinyqabenchmarkpp"></a>
    <a href="https://github.com/vincentkoc/tiny_qa_benchmark_pp/blob/main/LICENSE"><img alt="Licencia" src="https://img.shields.io/github/license/vincentkoc/tiny_qa_benchmark_pp"></a>
    <a href="https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp"><img alt="Conjunto de datos de Hugging Face" src="https://img.shields.io/badge/ü§ó%20Dataset-Tiny%20QA%20Benchmark%2B%2B-blue"></a>
    <!-- Considera a√±adir una insignia de flujo de trabajo de GitHub Actions si tienes CI configurada -->
    <!-- ej.: <a href="YOUR_WORKFLOW_LINK"><img alt="Estado de la compilaci√≥n" src="YOUR_WORKFLOW_BADGE_SVG_LINK"></a> -->
</div>

<p align="center">
    <a href="https://github.com/vincentkoc/tiny_qa_benchmark_pp"><b>GitHub</b></a> ‚Ä¢
    <a href="https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp"><b>Conjunto de datos de Hugging Face</b></a> ‚Ä¢
    <!-- Enlace al art√≠culo cuando est√© disponible -->
    <!-- <a href="#"><b>Art√≠culo (Enlace pr√≥ximamente)</b></a> ‚Ä¢ -->
    <a href="https://pypi.org/project/tinyqabenchmarkpp/"><b>PyPI</b></a>
</p>

<hr>
<!-- Opcional: Si tienes una imagen en miniatura del proyecto, puedes a√±adirla aqu√≠ -->
<!-- <p align="center"><img alt="Miniatura de TQB++" src="path/to/your/thumbnail.png" width="700"></p> -->

**Tiny QA Benchmark++ (TQB++)** es un conjunto de evaluaci√≥n ultraligero y un paquete de Python dise√±ado para exponer fallos cr√≠ticos en sistemas de Modelos de Lenguaje Grandes (LLM) en cuesti√≥n de segundos. Sirve como pruebas unitarias de software para LLM, ideal para comprobaciones r√°pidas de CI/CD, ingenier√≠a de prompts y garant√≠a de calidad continua en LLMOps modernos, para ser utilizado junto con herramientas de evaluaci√≥n de LLM existentes como [Opik](https://github.com/comet-ml/opik/).

Este repositorio contiene la implementaci√≥n oficial y los conjuntos de datos sint√©ticos para el art√≠culo: *Tiny QA Benchmark++: Micro Gold Dataset with Synthetic Multilingual Generation for Rapid LLMOps Smoke Tests*.

**Art√≠culo:** (Los detalles y el enlace a la preimpresi√≥n se proporcionar√°n aqu√≠ una vez publicados)

- **Hugging Face Hub:** [datasets/vincentkoc/tiny_qa_benchmark_pp](https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp)
- **Repositorio de GitHub:** [vincentkoc/tiny_qa_benchmark_pp](https://github.com/vincentkoc/tiny_qa_benchmark_pp)

## Caracter√≠sticas Principales

*   **N√∫cleo Inmutable Gold Standard:** Un conjunto de datos de Preguntas y Respuestas (QA) en ingl√©s de 52 √≠tems elaborado a mano (`core_en`) para pruebas de regresi√≥n deterministas de [datasets/vincentkoc/tiny_qa_benchmark](https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark) anteriores.
*   **Kit de Herramientas de Personalizaci√≥n Sint√©tica:** Un script de Python (`tools/generator`) que utiliza LiteLLM para generar micro-benchmarks a medida bajo demanda para cualquier idioma, tema o dificultad.
*   **Metadatos Estandarizados:** Artefactos empaquetados en formato Croissant JSON-LD (`metadata/`) para su descubrimiento y carga autom√°tica por herramientas y motores de b√∫squeda.
*   **Ciencia Abierta:** Todo el c√≥digo (generador, scripts de evaluaci√≥n) y el conjunto de datos principal en ingl√©s se publican bajo la licencia Apache-2.0. Los paquetes de datos generados sint√©ticamente tienen una licencia personalizada de solo evaluaci√≥n.
*   **Alineaci√≥n con LLMOps:** Dise√±ado para una f√°cil integraci√≥n en pipelines de CI/CD, flujos de trabajo de ingenier√≠a de prompts, detecci√≥n de deriva multiling√ºe y paneles de observabilidad.
*   **Paquetes Multiling√ºes:** Paquetes preconstruidos para numerosos idiomas, incluyendo ingl√©s, franc√©s, espa√±ol, portugu√©s, alem√°n, chino, japon√©s, turco, √°rabe y ruso.

## Instalaci√≥n

El kit de herramientas TQB++ (incluyendo el generador de conjuntos de datos y las utilidades de evaluaci√≥n) se puede instalar como un paquete de Python desde PyPI.

### Generaci√≥n de Conjuntos de Datos Sint√©ticos (paquete de python)

```bash
pip install tinyqabenchmarkpp
```

(Nota: Aseg√∫rate de tener Python 3.8+ y pip instalados. El nombre exacto del paquete en PyPI puede variar; por favor, comprueba los enlaces oficiales del proyecto si este comando no funciona.)

Una vez instalado, deber√≠as poder usar los scripts del generador y de evaluaci√≥n desde tu l√≠nea de comandos o importar funcionalidades en tus proyectos de Python.

## Carga de Conjuntos de Datos con `datasets` de Hugging Face

Los conjuntos de datos TQB++ est√°n disponibles en Hugging Face Hub y se pueden cargar f√°cilmente usando la biblioteca `datasets`. Esta es la forma recomendada de acceder a los datos.

```python
from datasets import load_dataset, get_dataset_config_names

# Descubrir configuraciones de conjuntos de datos disponibles (ej. core_en, pack_fr_40, etc.)
configs = get_dataset_config_names("vincentkoc/tiny_qa_benchmark_pp")
print(f"Configuraciones disponibles: {configs}")

# Cargar el conjunto de datos principal en ingl√©s (asumiendo que \'core_en\' es una configuraci√≥n)
if "core_en" in configs:
    core_dataset = load_dataset("vincentkoc/tiny_qa_benchmark_pp", name="core_en", split="train")
    print(f"\\nCargados {len(core_dataset)} ejemplos de core_en:")
    # print(core_dataset[0]) # Imprimir el primer ejemplo
else:
    print("\\nNo se encontr√≥ la configuraci√≥n \'core_en\'.")

# Cargar un paquete sint√©tico espec√≠fico (ej. un paquete en franc√©s)
# Reemplaza \'pack_fr_40\' con un nombre de configuraci√≥n real de la lista `configs`
example_pack_name = "pack_fr_40" # u otro nombre de configuraci√≥n v√°lido
if example_pack_name in configs:
    synthetic_pack = load_dataset("vincentkoc/tiny_qa_benchmark_pp", name=example_pack_name, split="train")
    print(f"\\nCargados {len(synthetic_pack)} ejemplos de {example_pack_name}:")
    # print(synthetic_pack[0]) # Imprimir el primer ejemplo
else:
    print(f"\\nNo se encontr√≥ la configuraci√≥n \'{example_pack_name}\'. Por favor, elige entre las configuraciones disponibles.")

```

Para obtener informaci√≥n m√°s detallada sobre los conjuntos de datos, incluyendo su estructura y licencias espec√≠ficas, por favor consulta los archivos README dentro del directorio `data/` (es decir, `data/README.md`, `data/core_en/README.md` y `data/packs/README.md`).

## Estructura del Repositorio

*   `data/`: Contiene los conjuntos de datos QA.
    *   `core_en/`: El conjunto de datos original de 52 √≠tems en ingl√©s elaborado a mano.
    *   `packs/`: Paquetes de datos multiling√ºes y tem√°ticos generados sint√©ticamente.
*   `tools/`: Contiene scripts para la generaci√≥n y evaluaci√≥n de conjuntos de datos.
    *   `generator/`: El generador de conjuntos de datos QA sint√©ticos.
    *   `eval/`: Scripts y utilidades para evaluaci√≥n de modelos contra los conjuntos de datos TQB++.
*   `paper/`: El c√≥digo fuente LaTeX y archivos asociados para el art√≠culo de investigaci√≥n.
*   `metadata/`: Archivos de metadatos Croissant JSON-LD para los conjuntos de datos.
*   `LICENSE`: Licencia principal para la base de c√≥digo (Apache-2.0).
*   `LICENCE.data_packs.md`: Licencia personalizada para los paquetes de datos generados sint√©ticamente.
*   `LICENCE.paper.md`: Licencia para el contenido del art√≠culo.

## Escenarios de Uso

TQB++ est√° dise√±ado para diversos flujos de trabajo de LLMOps y evaluaci√≥n:

*   **Pruebas de Pipeline CI/CD:** √ösalo como prueba unitaria con herramientas de prueba de LLM para servicios LLM para detectar regresiones.
*   **Ingenier√≠a de Prompts y Desarrollo de Agentes:** Obt√©n retroalimentaci√≥n r√°pida al iterar en prompts o dise√±os de agentes.
*   **Integraci√≥n de Arn√©s de Evaluaci√≥n:** Codif√≠calo como un YAML de OpenAI Evals o un conjunto de datos de Opik para el seguimiento en el panel de control.
*   **Detecci√≥n de Deriva Multiling√ºe:** Monitoriza las regresiones de localizaci√≥n usando paquetes TQB++ multiling√ºes.
*   **Pruebas Adaptativas:** Sintetiza nuevos micro-benchmarks sobre la marcha adaptados a caracter√≠sticas espec√≠ficas o derivas de datos.
*   **Monitorizaci√≥n de Din√°micas de Ajuste Fino:** Rastrea la erosi√≥n del conocimiento o cambios de capacidad no deseados durante el ajuste fino.

## Citaci√≥n

Si usas TQB++ en tu investigaci√≥n o trabajo, por favor cita el TQB original y el art√≠culo de TQB++:

```bibtex
% Este conjunto de datos sint√©tico y generador
@misc{koctinyqabenchmarkpp,
  author       = {Vincent Koc},
  title        = {Tiny QA Benchmark++ (TQB++) Conjuntos de Datos y Kit de Herramientas},
  year         = {2025},
  publisher    = {Hugging Face & GitHub},
  doi          = {10.57967/hf/5531},
  howpublished = {\\url{https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark_pp}},
  note         = {Ver tambi√©n: \\url{https://github.com/vincentkoc/tiny_qa_benchmark_pp}}
}

% core_en.json original (52 en en)
@misc{koctinyqabenchmark_original,
  author       = {Vincent Koc},
  title        = {tiny_qa_benchmark},
  year         = {2025},
  publisher    = {Hugging Face},
  journal      = {Hugging Face Hub},
  doi          = {10.57967/hf/5417},
  url          = {https://huggingface.co/datasets/vincentkoc/tiny_qa_benchmark}
}
```

<!-- % Marcador de posici√≥n para la cita del art√≠culo de TQB++ JMLR - actualizar cuando est√© disponible
@article{koc2025tqb_pp,
  author       = {Vincent Koc},
  title        = {Tiny QA Benchmark$^{++}$: Micro Gold Dataset with Synthetic Multilingual Generation for Rapid LLMOps Smoke Tests},
  journal      = {Journal of Machine Learning Research (pendiente)},
  year         = {2025},
  volume       = {XX},
  number       = {X},
  pages        = {X-XX},
  url          = {http://jmlr.org/papers/vXX/koc25a.html} % URL de ejemplo
} -->

## Licencia
El c√≥digo en este repositorio (incluyendo el generador y los scripts de evaluaci√≥n) y el conjunto de datos `data/core_en` y cualquier otra cosa no mencionada con una licencia est√°n licenciados bajo la Licencia Apache 2.0. Consulta el archivo `LICENSE` para m√°s detalles.

Los paquetes de datos generados sint√©ticamente en `data/packs/` se distribuyen bajo una licencia personalizada "Solo Evaluaci√≥n, No Comercial, Sin Derivadas". Consulta `LICENCE.data_packs.md` para m√°s detalles.

Los archivos de metadatos Croissant JSON-LD en `metadata/` est√°n disponibles bajo CC0-1.0.

El contenido del art√≠culo en `paper/` est√° sujeto a sus propios t√©rminos de licencia, detallados en `LICENCE.paper.md`. 